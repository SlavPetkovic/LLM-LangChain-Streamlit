{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import streamlit as st\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from lib.core import DataLoader, Config, Logger\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import logging.config\n",
    "import logging.handlers\n",
    "\n",
    "# Usage\n",
    "config = Config('../parameters/config.json')\n",
    "api_key = config.get_api_key()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T01:50:51.928663800Z",
     "start_time": "2023-12-03T01:50:51.889205100Z"
    }
   },
   "id": "adc445dab99a5114"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "logger = Logger('../parameters/logs.ini').get_logger()\n",
    "\n",
    "loader = DataLoader(file_path='../data/TroutStocking.pdf')\n",
    "data = loader.load()\n",
    "\n",
    "\n",
    "try:\n",
    "    text_contents = [doc.page_content for doc in data]\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error processing document contents: {e}\")\n",
    "\n",
    "\n",
    "def chunk_data(data, chunk_size= 256, chunk_overlap=20):\n",
    "    try:\n",
    "        # Initialize the text splitter\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size = chunk_size,\n",
    "            chunk_overlap= chunk_overlap,\n",
    "            length_function=len)\n",
    "        chunks = text_splitter.create_documents(text_contents)\n",
    "        logging.info(f\"Data chunking successful. Number of chunks: {len(chunks)}\")\n",
    "        return chunks\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in chunking data: {e}\")\n",
    "\n",
    "chunks = chunk_data(data, chunk_size= 256, chunk_overlap=20)\n",
    "def create_embeddings(chunks):\n",
    "    try:\n",
    "        config = Config('../parameters/config.json')\n",
    "        api_key = config.get_api_key()\n",
    "        logger.info(\"Creating embeddings...\")\n",
    "        embeddings = OpenAIEmbeddings(api_key=api_key)\n",
    "        vector_store = Chroma.from_documents(chunks, embeddings)\n",
    "        logger.info(\"Embeddings created successfully.\")\n",
    "        return vector_store\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating embeddings: {e}\")\n",
    "\n",
    "def prompt(vector_store, query,k):\n",
    "    try:\n",
    "        logger.info(f\"Processing query: {query}\")\n",
    "        # Set up the language model and retriever\n",
    "        llm = ChatOpenAI(api_key=api_key, model_name='gpt-4-1106-preview', temperature=1)\n",
    "        retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': k})\n",
    "        # Create and run the retrieval chain\n",
    "        chain = RetrievalQA.from_chain_type(llm=llm, chain_type='stuff', retriever=retriever)\n",
    "        answer = chain.run(query)\n",
    "        logger.info(\"Query processed successfully.\")\n",
    "        return answer\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in processing query: {e}\")   \n",
    "        \n",
    "def embedding_cost(texts):\n",
    "    try:\n",
    "        logger.info(\"Calculating embedding cost...\")\n",
    "        # Import tiktoken module\n",
    "        import tiktoken\n",
    "        enc = tiktoken.encoding_for_model('text-embedding-ada-002')\n",
    "        # Calculate total tokens\n",
    "        total_tokens = sum([len(enc.encode(page.page_content)) for page in texts])\n",
    "        cost = total_tokens / 1000 * 0.0004\n",
    "        # Log the calculated cost\n",
    "        logger.info(f'Total Tokens: {total_tokens}')\n",
    "        logger.info(f'Embedding Cost in USD: {cost:.6f}')\n",
    "        return cost\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in calculating embedding cost: {e}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3b3beffa9ff7463"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "26135b445938eab2"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "vector_store = create_embeddings(chunks)\n",
    "k=3"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T01:46:07.783158800Z",
     "start_time": "2023-12-03T01:46:07.768974800Z"
    }
   },
   "id": "57b835babe29a912"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = 'WHat bodies of water are in lumkin county?'\n",
    "answer = prompt(vector_store, query,k)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbe66f4ec88a1990"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
