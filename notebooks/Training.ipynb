{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "##                                      VectorDatasets\n",
    "![VectorDB](../assets/PineCone.png)\n",
    "\n",
    "A vector database stores and manages data in the form of vectors. These vectors represent complex data items such as images, text,\n",
    " and audio files in a format that is more conducive to certain types of processing like similarity searches.\n",
    "\n",
    "- **Specialized in Similarity Searches-** Ideal for finding 'similar' items, crucial for recommendation systems and image recognition.\n",
    "- **Leveraging Machine Learning-** Uses ML models to transform data into vectors for semantic-based indexing and retrieval.\n",
    "- **Fast Indexing and Retrieval-** Enables quick responses in real-time applications through specialized indexing.\n",
    "- **Scalable for Big Data-** Well-suited for large volumes, facilitating horizontal scalability in big data environments.\n",
    "- **Integration with Existing Systems-** Can be merged with current databases and data processing pipelines.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a92dbe2cb2cbf35"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Working with Pinecone Vector Database\n",
    "Sets up a Python environment to use the Pinecone vector database service, including importing necessary libraries, loading environment variables for security, and initializing the Pinecone service with an API key."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22b7a0e6571b4349"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9d3f4ffd-cc84-49ce-a06a-1bf3598f34cb\n"
     ]
    },
    {
     "data": {
      "text/plain": "VersionResponse(server='2.0.11', client='2.2.4')"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Dependencies\n",
    "import pinecone\n",
    "from langchain.vectorstores import Pinecone\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import PyPDF2\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "# Getting pinecone api key and environment\n",
    "load_dotenv(find_dotenv(),  override=True)\n",
    "api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "env = os.getenv(\"PINECONE_ENV\")\n",
    "print(api_key) \n",
    "pinecone.init(api_key = api_key, environment= env)\n",
    "pinecone.info.version()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T08:18:13.260842300Z",
     "start_time": "2023-12-07T08:18:12.412444300Z"
    }
   },
   "id": "b31689170cea86f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check if there is an index with the given name\n",
    "indexes = pinecone.list_indexes()\n",
    "print(indexes)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ff03095251d51e1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# deleting all indexes\n",
    "for i in indexes:\n",
    "    pinecone.delete_index(i)\n",
    "    print(\"Index Deleted\")\n",
    "indexes = pinecone.list_indexes()\n",
    "print(f'There are: {len(indexes)} indexes in database')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "436eefe0825c4c60"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create Pinecone index\n",
    "index_name = \"fishing\"\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    print(f'Create index {index_name}')\n",
    "    pinecone.create_index(index_name,dimension=1536, metric='cosine', pods=1, pod_type='p1.x2')\n",
    "    print('Index Created')\n",
    "else:\n",
    "    print(\"Index exists\")\n",
    "pinecone.list_indexes()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "310a96e8cba6c3d7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read the PDF file\n",
    "pdf_reader = PyPDF2.PdfReader('../data/TroutStocking.pdf')\n",
    "\n",
    "# Extract text from each page and concatenate it\n",
    "full_text = \"\"\n",
    "for page in pdf_reader.pages:\n",
    "    full_text += page.extract_text() + \"\\n\"\n",
    "\n",
    "print(full_text)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "830d47ca0f40bee7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize the text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100, # Number of chunks to split the text into\n",
    "    chunk_overlap=20, # Overlapping between chunks\n",
    "    length_function=len)\n",
    "\n",
    "# Create chunks from the extracted text\n",
    "chunks = text_splitter.create_documents([full_text])\n",
    "# Rerun first chunk\n",
    "print(chunks[0])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49e41057085ac87c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating Embeddings\n",
    "\n",
    "- Definition: Embeddings are vector representations of complex data (like words, images, sounds) in a lower-dimensional space.\n",
    "- Purpose: They transform data into a format understandable by machine learning models, preserving essential characteristics.\n",
    "- NLP Use: In natural language processing, word embeddings capture semantic relationships between words.\n",
    "- Examples: Tools like Word2Vec, GloVe, and BERT are used for creating word embeddings.\n",
    "- Applications: Beyond text, used in image processing and recommendation systems to represent visual features or user preferences.\n",
    "- Advantages: Facilitate efficient model processing and capture deep similarities and relationships in data.\n",
    "- Training: Can be pre-trained on large datasets or trained from scratch for specific tasks."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72a435754a622106"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create embeddings\n",
    "from langchain.embeddings import  OpenAIEmbeddings\n",
    "# Getting OpenAI api key and environment\n",
    "load_dotenv(find_dotenv(),  override=True)\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(api_key) \n",
    "\n",
    "embeddings = OpenAIEmbeddings(api_key = api_key)\n",
    "vector = embeddings.embed_query(chunks[0].page_content)\n",
    "Pinecone.from_documents(chunks, embeddings,index_name = index_name)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b7460a437a92f8a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Asking Question and performing Similarity Searches\n",
    "![VectorDB](../assets/Similarity.png)\n",
    "Vector similarity search is a method used in computing to find elements in a database that are similar to a given query item. This process is particularly relevant in the context of vector databases, where data is represented as vectors - lists of numbers that encode information about the items. Hereâ€™s a basic explanation\n",
    "- **Vector Representation -** In a vector similarity search, items in the database (like text, images, or sounds) are transformed into vectors using algorithms. These vectors are numerical representations that capture the essential features of the items.\n",
    "\n",
    "- **Measuring Similarity -** The core idea is to measure how 'close' two vectors are to each other. This closeness is typically determined by calculating the distance or angle between vectors. Common measures include Euclidean distance, cosine similarity, and Manhattan distance.\n",
    "\n",
    "- **Querying -** When a query is made (for instance, a search for an image), the query item is also converted into a vector. The search algorithm then looks through the database to find vectors that are closest to the query vector.\n",
    "\n",
    "- **Applications -** This method is widely used in various fields like recommendation systems (suggesting products or content similar to what a user likes), image and voice recognition systems, and natural language processing (finding documents or texts similar to a given piece of text).\n",
    "\n",
    "- **Advantages -** Vector similarity searches are powerful because they can find items that are 'semantically' similar, not just exact matches. This allows for more nuanced and context-aware results.\n",
    "\n",
    "- **Challenges-** One challenge in vector similarity search is the computational cost, especially with very large databases. Efficient algorithms and indexing strategies are crucial for maintaining fast and accurate search results.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3568d041ea35d1ff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Asking Questions ( Similarity Search)\n",
    "vector_store = Pinecone.from_documents(chunks,embeddings,index_name=index_name)\n",
    "query = 'Give me all bodies of watter in Lumpkin county'\n",
    "results = vector_store.similarity_search(query)\n",
    "print(results)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1eac8e5d69637fc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Clustering based on similarity\n",
    "The concept of clustering in a vector space, where items are grouped based on similarity. \n",
    "The entire diagram can be thought of as a vector space, which is a mathematical space where each item (represented by a dot) is a vector. The position of each dot indicates its relationship to the others.\n",
    "\n",
    "![VectorDB](../assets/VectorGroups.png)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48b11697d9232dbf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CHROMA VectorDB Example\n",
    "\n",
    "Chroma is an open-source vector database designed to store and utilize embeddings for various applications, such as building large language model (LLM) applications. It's engineered to make knowledge, facts, and skills easily pluggable into LLMs, streamlining the development of AI applications by efficiently handling vector similarity searches crucial for recommendation systems, image recognition, and natural language processing tasks."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "efb0492e1bdaeaac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# load the document and split it into chunks\n",
    "loader = TextLoader(\"../data/AI_And_Morality.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "# split it into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=512, chunk_overlap=20)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# create the open-source embedding function\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# load it into Chroma\n",
    "db = Chroma.from_documents(docs, embedding_function)\n",
    "\n",
    "# query it\n",
    "query = \"Who is Nick Bostrom?\"\n",
    "docs = db.similarity_search(query)\n",
    "\n",
    "# print results\n",
    "print(docs[0].page_content)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29c5ff78212b280"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7e848de108bcfb0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
